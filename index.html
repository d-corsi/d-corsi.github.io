<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Davide  Corsi</title>
    <meta name="author" content="Davide  Corsi">
    <meta name="description" content="Davide Corsi academic website.">
    <meta name="keywords" content="Academic website, Formal Verification of DNNs, Safe DRL">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A4%96&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://d-corsi.github.io/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item active">
                <a class="nav-link" href="/">Home<span class="sr-only">(current)</span></a>
              </li>
            

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">Resume</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      <!-- about.html -->
      <div class="post">
        <header class="post-header">
          <h1 class="post-title" align="center">
           <span class="font-weight-bold">Davide</span>  Corsi
          </h1>
          <p class="desc" align="center"><strong>Postdoctoral</strong> Research Associate<br></p>
        </header>
         
        <article>
          <div class="profile float-right">

              <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/D3-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/D3-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/D3-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/D3.jpg" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="D3.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

            <div class="address">
              <p> 📍 Irvine, CA, USA </p>
            </div>
          </div>

          <div class="clearfix">
            <p>I am a Postdoctoral Researcher at <a href="https://uci.edu" rel="external nofollow noopener" target="_blank">University of California: Irvine</a>, in the <a href="https://indylab.org" rel="external nofollow noopener" target="_blank">Intelligent Dynamics Lab</a> under the supervision of <a href="https://royf.org" rel="external nofollow noopener" target="_blank">Prof. Roy Fox</a>. Previously, I worked as a visiting researcher under the supervision of <a href="https://www.katz-lab.com/" rel="external nofollow noopener" target="_blank">Prof. Guy Katz</a> at the Hebrew University of Jerusalem. I obtained my PhD at the University of Verona advised by <a href="http://profs.sci.univr.it/~farinelli/" rel="external nofollow noopener" target="_blank">Prof. Alessandro Farinelli</a>.</p>

<p>My <strong>research interests</strong> center on advancing deep reinforcement learning for robotics in safety-critical settings. I work on both sides of safety: training-time methods (<strong>constrained RL</strong> and <strong>safety shields</strong>) and post-training assurance via <strong>formal verification of neural networks</strong>. Recently, I’ve been integrating <strong>foundation models</strong> (LLMs and VLMs/VLAMs) with RL for robotic control, and developing world models so agents can not only react but <strong>predict</strong>. A key focus is sim-to-real transfer and low-latency deployment on real platforms (drones, manipulators, aquatic robots), with an emphasis on measurable reliability and open, reproducible artifacts. My goal is to bridge theory and practice to deliver robust systems with clear safety guarantees. For more, see the publications page.<a href="https://d-corsi.github.io/publications/">publications page</a>.</p>

<font size="4"><strong>Places</strong></font>
<font size="1"><strong>(📍)</strong></font>
<font size="4"><strong>:</strong></font>

<ul>
  <li>🇺🇸 University of California: Irvine, United States</li>
  <li>🇮🇱 The Hebrew University of Jerusalem, Israel</li>
  <li>🇮🇹 University of Verona, Italy</li>
</ul>

          </div>

          <!-- News -->
          <br>
          <br>
          <h2><a href="/news/" style="color: inherit;">News 📢</a></h2>          
          <div class="news">
            <div class="table-responsive" style="max-height: 20vw">
              <table class="table table-sm table-borderless">
               
                <tr>
                  <!--<th scope="row">Jan 1, 2025</th>-->
                  <th scope="row">2025</th>
                  <td>
                     <strong>July</strong>

<ul>
  <li>Excited to share two new papers this month! ✨ Our work <em>“Analyzing Adversarial Inputs in Deep Reinforcement Learning”</em> has been accepted at <strong>AISoLA 2025</strong>. You can find it <a href="https://arxiv.org/abs/2402.05284.pdf" rel="external nofollow noopener" target="_blank">here</a>. Another highlight: <em>“Efficient Dynamic Shielding for Parametric Safety Specifications”</em> has been accepted at <strong>ATVA 2025</strong>! You can read it <a href="https://arxiv.org/abs/2505.22104.pdf" rel="external nofollow noopener" target="_blank">here</a>.</li>
</ul>

 <strong>June</strong>

<ul>
  <li>Really excited to kick off my participation in the <a href="https://www.darpa.mil/research/programs/safron" rel="external nofollow noopener" target="_blank">DARPA SAFRON project</a> 🤖.<br>
In this project, we will investigate how to integrate foundation models (LLMs, VLMs, and VLAMs) for robotic control, with a special emphasis on the <strong>safety</strong> of these systems. These models cannot simply be treated as black boxes, and I’m thrilled to explore new ways to make them safer and more reliable!</li>
</ul>

 <strong>May</strong>

<ul>
  <li>Thrilled to announce that our paper <em>“Explanations for Unrealizability of Infinite-State Safety Shields”</em> has been accepted at <strong>KR 2025</strong> 🎉. You can check it out <a href="https://arxiv.org/abs/2507.23603.pdf" rel="external nofollow noopener" target="_blank">here</a>.</li>
</ul>

 <strong>February</strong>

<ul>
  <li>Our paper <em>“Realizable Continuous-Space Shields for Safe Reinforcement Learning”</em> has been accepted at <strong>L4DC 2025</strong> 🚀. See the paper <a href="https://arxiv.org/pdf/2410.02038" rel="external nofollow noopener" target="_blank">here</a>.</li>
</ul>
 
                  </td>
                </tr> 
                <tr>
                  <!--<th scope="row">Jan 1, 2024</th>-->
                  <th scope="row">2024</th>
                  <td>
                     <strong>December</strong>

<ul>
  <li>Thrilled to announce that our paper <em>“Shield Synthesis for LTL Modulo Theories”</em> has been accepted at <a href="https://aaai.org/aaai-conference/" rel="external nofollow noopener" target="_blank">AAAI 2025</a> 🎉. You can find the paper <a href="https://ojs.aaai.org/index.php/AAAI/article/view/33660" rel="external nofollow noopener" target="_blank">here</a>. Many thanks to my amazing collaborators from Israel and Spain for this work!</li>
</ul>

 <strong>September</strong>

<ul>
  <li>The result of my collaboration with the <a href="https://en.huji.ac.il/" rel="external nofollow noopener" target="_blank">Hebrew University of Jerusalem</a> has been accepted at <a href="https://iconip2024.org" rel="external nofollow noopener" target="_blank">ICONIP 2024</a>, we are excited to present our new paper <em>Enforcing Specific Behaviours via Constrained DRL and Scenario-Based Programming</em>! 🚀</li>
</ul>

 <strong>July</strong>

<ul>
  <li>Excited to share that my first work at the <a href="https://uci.edu" rel="external nofollow noopener" target="_blank">University of California: Irvine</a> has been accepted in <a href="https://rl-conference.cc" rel="external nofollow noopener" target="_blank">RLC 2024</a> 😍. What an amazing collaboration with colleagues from all over the world <em>Verification-Guided Shielding for Deep Reinforcement Learning</em>!</li>
</ul>

 <strong>January</strong>

<ul>
  <li>
    Start of a new job at the <a href="https://uci.edu" rel="external nofollow noopener" target="_blank">University of California: Irvine</a> in the <em>Intelligent Dynamics Lab</em> headed by <a href="https://royf.org" rel="external nofollow noopener" target="_blank">Prof. Roy Fox</a>. Really excited about this new adventure! 🇺🇸
  </li>
  <li>
    Delight to share that our new paper <em>“Enumerating Safe Regions in Deep Neural Networks with Provable Probabilistic Guarantees”</em> has been accepted at <a href="https://aaai.org/aaai-conference/" rel="external nofollow noopener" target="_blank">AAAI 2024</a> ✈️.
  </li>
</ul>
 
                  </td>
                </tr> 
                <tr>
                  <!--<th scope="row">Jan 1, 2023</th>-->
                  <th scope="row">2023</th>
                  <td>
                     <strong>July</strong>

<ul>
  <li>Our paper <em>“Formal Explainability of DNN-Based Reactive Systems”</em> has been accepted at <a href="https://fmcad.org/FMCAD23/" rel="external nofollow noopener" target="_blank">FMCAD 2023</a> 😍.</li>
</ul>

 <strong>June</strong>

<ul>
  <li>Our paper <em>“Constrained Reinforcement Learning and Formal Verification for Safe Colonoscopy Navigation”</em> has been accepted at <a href="https://ieee-iros.org/" rel="external nofollow noopener" target="_blank">IROS 2023</a> 🤖.</li>
</ul>

 <strong>May</strong>

<ul>
  <li>I successfully defended my PhD thesis. A big thanks to my advisor <a href="http://profs.sci.univr.it/~farinelli/" rel="external nofollow noopener" target="_blank">Prof. Alessandro Farinelli</a> and to the thesis committee <a href="https://www.st.ewi.tudelft.nl/mtjspaan/" rel="external nofollow noopener" target="_blank">Prof. Matthijs Spaan</a>, <a href="http://robertocapobianco.com/" rel="external nofollow noopener" target="_blank">Prof. Roberto Capobianco</a>, and <a href="https://scholar.google.com/citations?user=_90LQXQAAAAJ&amp;hl=it" rel="external nofollow noopener" target="_blank">Prof. Domenico Bloisi</a> 🎓.</li>
</ul>

 <strong>April</strong>

<ul>
  <li>Our paper <em>“The #DNN-Verification Problem: Counting Unsafe Inputs for Deep Neural Networks”</em> has been accepted at <a href="https://ijcai-23.org/" rel="external nofollow noopener" target="_blank">IJCAI 2023</a> (15% acceptance rate) 🤩.</li>
</ul>

 <strong>January</strong>

<ul>
  <li>Our paper <em>“Verifying Learning-Based Robotic Navigation Systems”</em> in collaboration with <a href="https://www.katz-lab.com/" rel="external nofollow noopener" target="_blank">The Katz Lab</a> has been accepted at <a href="https://www.etaps.org/2023/conferences/" rel="external nofollow noopener" target="_blank">ETAPS TACAS 2023</a> 🚀.</li>
</ul>
 
                  </td>
                </tr> 
                <tr>
                  <!--<th scope="row">Jan 1, 2022</th>-->
                  <th scope="row">2022</th>
                  <td>
                     <strong>September</strong>

<ul>
  <li>As a result of the research visit at the Hebrew University of Jerusalem, we submitted the papers <em>“Verifying Learning-Based Robotic Navigation Systems</em>” and <em>“Constrained Reinforcement Learning for Robotics via Scenario-Based Programming</em>” at two international conferences.</li>
</ul>

 <strong>February</strong>

<ul>
  <li>Excited to share that I’ll start a reaserach visit at the <a href="https://en.huji.ac.il/" rel="external nofollow noopener" target="_blank">Hebrew University of Jerusalem</a>, under the supervision of <a href="https://www.katz-lab.com/" rel="external nofollow noopener" target="_blank">Prof. Guy Katz</a>. 🇮🇱</li>
</ul>

 <strong>January</strong>

<ul>
  <li>Our paper <em>“Exploring Safer Behaviors for Deep Reinforcement Learning”</em> has been accepted at <a href="https://aaai.org/conference/aaai/aaai-22/" rel="external nofollow noopener" target="_blank">AAAI 2022</a> (15% acceptance rate) 🤩.</li>
</ul>
 
                  </td>
                </tr> 
                <tr>
                  <!--<th scope="row">Jan 1, 2021</th>-->
                  <th scope="row">2021</th>
                  <td>
                     <strong>June</strong>

<ul>
  <li>Our two papers <em>“Benchmarking Safe Deep Reinforcement Learning in Aquatic Navigation”</em> and <em>“Safe Reinforcement Learning using Formal Verification for Tissue Retraction in Autonomous Robotic-Assisted Surgery”</em> have been accepted at <a href="https://www.iros2021.org/" rel="external nofollow noopener" target="_blank">IROS 2021</a> 🤖.</li>
</ul>

 <strong>May</strong>

<ul>
  <li>
    Proud to share that my first main author paper <em>“Formal Verification of Neural Networks for Safety-Critical Tasks in Deep Reinforcement Learning”</em> has been accepted at <a href="https://www.auai.org/uai2021/" rel="external nofollow noopener" target="_blank">UAI 2021</a> 😍.
  </li>
  <li>
    Our paper <em>“Genetic Soft Updates for Policy Evolution in Deep Reinforcement Learning”</em> has been accepted at <a href="https://iclr.cc/Conferences/2021" rel="external nofollow noopener" target="_blank">ICLR 2021</a>.
  </li>
</ul>
 
                  </td>
                </tr> 
              </table>
            </div> 
          </div>

          <!-- Latest posts -->
          

          <!-- Selected papers -->
          <br>
          <br>
          <h2><a href="/publications/" style="color: inherit;">Selected publications 📚</a></h2>
          <div class="publications">
            <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">

        <div class="col-sm-3 abbr"><abbr class="badge">L4DC</abbr></div>

        <!-- Entry bib key -->
        <div id="kim2025realizable" class="col-sm-7">
        <!-- Title -->
        <div class="title"><a href="https://par.nsf.gov/biblio/10614736" rel="external nofollow noopener" target="_blank">Realizable Continuous-Space Shields for Safe Reinforcement Learning</a></div>
        <!-- Author -->
        <div class="author">
        

        Kim Kyungmin, <em>Davide Corsi</em>, Andoni Rodriguez, JB Lanier, Benjami Parellada, Pierre Baldi, Cesar Sanchez, and
          <span class="more-authors" title="click to view 1 more author" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '1 more author' ? 'Roy Fox' : '1 more author';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">1 more author</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In 7th Annual Conference on Learning for Dynamics and Control</em>, 2025
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://par.nsf.gov/biblio/10614736" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
            <a href="https://arxiv.org/pdf/2410.02038" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-altmetric-id="" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
            <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>While Deep Reinforcement Learning (DRL) has achieved remarkable success across various domains, it remains vulnerable to occasional catastrophic failures without additional safeguards. An effective solution to prevent these failures is to use a shield that validates and adjusts the agent’s actions to ensure compliance with a provided set of safety specifications. For real-world robotic domains, it is essential to define safety specifications over continuous state and action spaces to accurately account for system dynamics and compute new actions that minimally deviate from the agent’s original decision. In this paper, we present the first shielding approach specifically designed to ensure the satisfaction of safety requirements in continuous state and action spaces, making it suitable for practical robotic applications. Our method builds upon realizability, an essential property that confirms the shield will always be able to generate a safe action for any state in the environment. We formally prove that realizability can be verified for stateful shields, enabling the incorporation of non-Markovian safety requirements, such as loop avoidance. Finally, we demonstrate the effectiveness of our approach in ensuring safety without compromising the policy’s success rate by applying it to a navigation problem and a multi-agent particle environment1. Keywords: Shielding, Reinforcement Learning, Safety, Robotics</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">

        <div class="col-sm-3 abbr"><abbr class="badge">RLC</abbr></div>

        <!-- Entry bib key -->
        <div id="corsi2024verification" class="col-sm-7">
        <!-- Title -->
        <div class="title"><a href="https://arxiv.org/abs/2406.06507" rel="external nofollow noopener" target="_blank">Verification-Guided Shielding for Deep Reinforcement Learning</a></div>
        <!-- Author -->
        <div class="author">
        

        <em>Davide Corsi</em>, Guy Amir, Andoni Rodriguez, Cesar Sanchez, Guy Katz, and Roy Fox</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In The 1st Reinforcement Learning Conference</em>, 2024
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2406.06507" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
            <a href="https://arxiv.org/pdf/2406.06507.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-altmetric-id="" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
            <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>In recent years, Deep Reinforcement Learning (DRL) has emerged as an effective approach to solving real-world tasks. However, despite their successes, DRL-based policies suffer from poor reliability, which limits their deployment in safety-critical domains. As a result, various methods have been put forth to address this issue by providing formal safety guarantees. Two main approaches include shielding and verification. While shielding ensures the safe behavior of the policy by employing an external online component (i.e., a “shield”) that overruns potentially dangerous actions, this approach has a significant computational cost as the shield must be invoked at runtime to validate every decision. On the other hand, verification is an offline process that can identify policies that are unsafe, prior to their deployment, yet, without providing alternative actions when such a policy is deemed unsafe. In this work, we present verification-guided shielding – a novel approach that bridges the DRL reliability gap by integrating these two methods. Our approach combines both formal and probabilistic verification tools to partition the input domain into safe and unsafe regions. In addition, we employ clustering and symbolic representation procedures that compress the unsafe regions into a compact representation. This, in turn, allows to temporarily activate the shield solely in (potentially) unsafe regions, in an efficient manner. Our novel approach allows to significantly reduce runtime overhead while still preserving formal safety guarantees. We extensively evaluate our approach on two benchmarks from the robotic navigation domain, as well as provide an in-depth analysis of its scalability and completeness.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">

        <div class="col-sm-3 abbr"><abbr class="badge">AAAI</abbr></div>

        <!-- Entry bib key -->
        <div id="marzari2023enumerating" class="col-sm-7">
        <!-- Title -->
        <div class="title"><a href="https://arxiv.org/abs/2308.09842" rel="external nofollow noopener" target="_blank">Enumerating Safe Regions in Deep Neural Networks with Provable Probabilistic Guarantees</a></div>
        <!-- Author -->
        <div class="author">
        

        Luca Marzari, <em>Davide Corsi</em>, Enrico Marchesini, Alessandro Farinelli, and Ferdinando Cicalese</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In The 38th AAAI Conference on Artificial Intelligence</em>, 2024
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2308.09842" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
            <a href="https://arxiv.org/pdf/2308.09842.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-altmetric-id="" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
            <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Identifying safe areas is a key point to guarantee trust for systems that are based on Deep Neural Networks (DNNs). To this end, we introduce the AllDNN-Verification problem: given a safety property and a DNN, enumerate the set of all the regions of the property input domain which are safe, i.e., where the property does hold. Due to the #P-hardness of the problem, we propose an efficient approximation method called ε-ProVe. Our approach exploits a controllable underestimation of the output reachable sets obtained via statistical prediction of tolerance limits, and can provide a tight (with provable probabilistic guarantees) lower estimate of the safe areas. Our empirical evaluation on different standard benchmarks shows the scalability and effectiveness of our method, offering valuable insights for this new type of verification of DNNs.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">

        <div class="col-sm-3 abbr"><abbr class="badge">IROS</abbr></div>

        <!-- Entry bib key -->
        <div id="pore2021safe" class="col-sm-7">
        <!-- Title -->
        <div class="title"><a href="https://ieeexplore.ieee.org/abstract/document/9636175/" rel="external nofollow noopener" target="_blank">Safe Reinforcement Learning Using Formal Verification for Tissue Retraction in Autonomous Robotic-Assisted Surgery</a></div>
        <!-- Author -->
        <div class="author">
        

        Ameya Pore*, <em>Davide Corsi*</em>, Enrico Marchesini*, Diego Dall’Alba, Alicia Casals, Alessandro Farinelli, and Paolo Fiorini</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In IEEE International Conference on Intelligent Robots and Systems</em>, 2021
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://ieeexplore.ieee.org/abstract/document/9636175/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-altmetric-id="" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
            <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Deep Reinforcement Learning (DRL) is a viable solution for automating repetitive surgical subtasks due to its ability to learn complex behaviours in a dynamic environment. This task automation could lead to reduced surgeon’s cognitive workload, increased precision in critical aspects of the surgery, and fewer patient-related complications. However, current DRL methods do not guarantee any safety criteria as they maximise cumulative rewards without considering the risks associated with the actions performed. Due to this limitation, the application of DRL in the safety-critical paradigm of robot-assisted Minimally Invasive Surgery (MIS) has been constrained. In this work, we introduce a Safe-DRL framework that incorporates safety constraints for the automation of surgical subtasks via DRL training. We validate our approach in a virtual scene that replicates a tissue retraction task commonly occurring in multiple phases of an MIS. Furthermore, to evaluate the safe behaviour of the robotic arms, we formulate a formal verification tool for DRL methods that provides the probability of unsafe configurations. Our results indicate that a formal analysis guarantees safety with high confidence such that the robotic instruments operate within the safe workspace and avoid hazardous interaction with other anatomical structures.</p>
          </div>
        </div>
      </div>
</li>
</ol>
          </div>


          <!-- Social -->
            <div class="social">
              <div class="contact-icons">
                <a href="mailto:%64%63%6F%72%73%69@%75%63%69.%65%64%75" title="email"><i class="fas fa-envelope"></i></a>
            <a href="https://scholar.google.com/citations?user=chv2d8IAAAAJ&amp;hl" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a>
            <a href="https://github.com/d-corsi" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a>
            <a href="https://twitter.com/dcorsi_" title="Twitter" rel="external nofollow noopener" target="_blank"><i class="fab fa-twitter"></i></a>
            

              </div>

              <div class="contact-note">
                Feel free to send an email about RL, Robotics and Formal Verification of DNN!

              </div>

            </div>
        </article>

</div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2025 Davide  Corsi. Last updated: September 09, 2025.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
